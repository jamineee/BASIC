# -*- coding: utf-8 -*-
"""app.py"""

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
import json
from openai import OpenAI
import os
# CSV íŒŒì¼ ë¡œë“œ
file_path = 'full_petition_df.csv'
data = pd.read_csv(file_path)

#ì‚¬ì§„ íŒŒì¼ ë¡œë“œ
from PIL import Image

#PIL íŒ¨í‚¤ì§€ì— ì´ë¯¸ì§€ ëª¨ë“ˆì„ í†µí•´ ì´ë¯¸ì§€ ì—´ê¸° 
# Image.open('ì´ë¯¸ì§€ ê²½ë¡œ')
assembly_img = Image.open('assembly_img.jpg')

col1,col2 = st.columns([2,3])
# ì œëª©
st.image(assembly_img)
st.write('ì‚¬ì§„ ì¶œì²˜: ëŒ€í•œë¯¼êµ­ êµ­íšŒ')
st.title("êµ­íšŒ êµ­ë¯¼ë™ì˜ ì²­ì› ëŒ€ì‹œë³´ë“œ")

# Tab ì„¤ì •
tab1, tab2 = st.tabs(['êµ­íšŒ êµ­ë¯¼ë™ì˜ ì²­ì› ì±—ë´‡', 'êµ­íšŒ êµ­ë¯¼ë™ì˜ ì²­ì› í˜„í™©'])

with tab1:
    # Tab A ë‚´ìš©
    #st.write('')
  
    os.environ["OPENAI_API_KEY"] = "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"  
  
    st.title("ë‹¹ì‹ ì˜ ì²­ì› ì‘ì„±ì„ ë„ì™€ë“œë¦½ë‹ˆë‹¤!")  

    if 'messages' not in st.session_state:  
        st.session_state.messages = [{"role":"system","content":"ë‹¹ì‹ ì€ êµ­íšŒ êµ­ë¯¼ë™ì˜ ì²­ì›ì˜ ì£¼ì œë¥¼ ìš”ì•½í•˜ê³ , ì •í•´ì§„ 18ê°€ì§€ì˜ ë¶„ë¥˜(1.ì •ì¹˜/ì„ ê±°/êµ­íšŒìš´ì˜ 2.ìˆ˜ì‚¬/ë²•ë¬´/ì‚¬ë²•ì œë„ 3.ì¬ì •/ì„¸ì¬/ê¸ˆìœµ/ì˜ˆì‚° 4.ì†Œë¹„ì/ê³µì •ê±°ë˜ 5.êµìœ¡ 6.ê³¼í•™ê¸°ìˆ /ì •ë³´í†µì‹  7.ì™¸êµ/í†µì¼/êµ­ë°©/ì•ˆë³´ 8.ì¬ë‚œ/ì•ˆì „/í™˜ê²½ 9.í–‰ì •/ì§€ë°©ìì¹˜ 10.ë¬¸í™”/ì²´ìœ¡/ê´€ê´‘/ì–¸ë¡  11.ë†ì—…/ì„ì—…/ìˆ˜ì‚°ì—…/ì¶•ì‚°ì—… 12.ì‚°ì—…/í†µìƒ 13.ë³´ê±´ì˜ë£Œ 14.ë³µì§€/ë³´í›ˆ 15.êµ­í† /í•´ì–‘/êµí†µ 16.ì¸ê¶Œ/ì„±í‰ë“±/ë…¸ë™ 17.ì €ì¶œì‚°/ê³ ë ¹í™”/ì•„ë™/ì²­ì†Œë…„/ê°€ì¡± 18.ê¸°íƒ€)ì— ë”°ë¼ ì²­ì›ì„ ë¶„ë¥˜í•´ì£¼ëŠ” ì¸ê³µì§€ëŠ¥ì´ì•¼. ë˜í•œ ì£¼ì œì™€ ë¬¸ì œ ìƒí™©ì„ ì„¤ëª…í•´ì¤¬ì„ë•Œ, ì²­ì›ì„ 1000ì ì´ìƒìœ¼ë¡œ ì™„ì„±ì‹œì¼œì£¼ëŠ” ì¼ë„ ìˆ˜í–‰í•´ì•¼í•´. ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ì¶° ì ì ˆí•œ ì‘ë‹µì„ ë‚´ì–´ì¤˜. ì²­ì› ìš”ì•½ì‹œì—ëŠ” ì²­ì› í…ìŠ¤íŠ¸ ë‚´ì—ì„œ ì£¼ì œì™€ ê´€ë ¨ëœ ìœ ì˜ë¯¸í•œ ë‹¨ì–´ë§Œ ì‚¬ìš©í•´ì„œ í…ìŠ¤íŠ¸ ë²„ë¸” ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì¤˜. ì´ë•Œ ì‚¬ìš©ë˜ëŠ” ë‹¨ì–´ëŠ” 30ë‹¨ì–´ë¥¼ ë„˜ì§€ ë§ì•„. ë„ˆê°€ ì‘ì„±í•œ ì²­ì› ì „ë¬¸ì´ë‚˜, ì…ë ¥ëœ ì²­ì› ì „ë¬¸ì´ë“ , ì „ë¬¸ì´ ì¡´ì¬í•˜ê¸°ë§Œ í•œë‹¤ë©´ í…ìŠ¤íŠ¸ ë²„ë¸” ì´ë¯¸ì§€ë¥¼ í•­ìƒ ì¶œë ¥í•´ì¤˜. ëª¨ë“  ì¶œë ¥ì€ ë‹¤ìŒì˜ í˜•ì‹ì„ ë”°ë¼ì„œ ì‘ì„±í•´ì¤˜. (í˜•ì‹: 1. ì£¼ì œ ìš”ì•½ 2. êµ­íšŒêµ­ë¯¼ë™ì˜ ì²­ì› ê¸°ë°˜ ë¶„ë¥˜ 3. ì²­ì› ìš”ì•½ ì‹œê°í™” ì´ë¯¸ì§€-ì›Œë“œí´ë¼ìš°ë“œ - ê°€ì¥ í•µì‹¬ì ì¸ ë‹¨ì–´ 15ê°œë§Œ ì‚¬ìš©í•´ì„œ ê·¸ë ¤ì¤˜. 4. ì²­ì› ì‘ì„±ì„ ìš”êµ¬í–ˆì„ê²½ìš°, ì²­ì›ì„ ì‘ì„±í•œ í›„ì— 3ë²ˆ ì‘ì—…ì„ ì§„í–‰í•´ì¤˜)"}
        ,{"role":"assistant","content":""}]  
  
    for msg in st.session_state.messages:
        if msg["role"] != "system":  # ì‹œìŠ¤í…œ ë©”ì‹œì§€ëŠ” ì œì™¸
            if msg["role"] == "assistant":
                st.write(f"ğŸ¤– {msg['content']}")
            elif msg["role"] == "user":
                st.write(f"ğŸ§‘ {msg['content']}")

    user_message = st.text_input("User:", key="text_input1")  
    
    if st.button("Send"):
    # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        if user_message.strip():
            st.session_state.messages.append({"role": "user", "content": user_message})
        
        # OpenAI ì‘ë‹µ ìƒì„±
            completion = client.chat.completions.create(
                model="gpt-4o",
                messages=st.session_state.messages
        )
            response = completion.choices[0].message.content
            st.session_state.messages.append({"role": "assistant", "content": response})


# ë©”ì‹œì§€ ì¶œë ¥ (system ë©”ì‹œì§€ ì œì™¸, ì¤‘ë³µ ì¶œë ¥ ë°©ì§€)
    for msg in reversed(st.session_state.messages):
        if msg["role"] != "system":  # system ë©”ì‹œì§€ ì œì™¸
            with st.chat_message(msg['role']):
                st.write(msg['content'])

with tab2:
    # Tab B ë‚´ìš©
    st.write('êµ­íšŒ êµ­ë¯¼ë™ì˜ ì²­ì› ëŒ€ì‹œë³´ë“œ')
    col1, col2 = st.columns([2, 3])

    # Column 1
    with col1:
        st.subheader("ì£¼ì œë³„ ì²­ì› ë¶„ë¥˜")
        grouped_by_topic = data.groupby("ë¶„ì•¼").size()  # ì²­ì› ì£¼ì œë³„ ê±´ìˆ˜ ì§‘ê³„
        fig1, ax1 = plt.subplots()
        ax1.pie(
            grouped_by_topic, 
            labels=grouped_by_topic.index, 
            autopct='%1.1f%%', 
            startangle=140, 
            colors=plt.cm.Paired.colors
        )
        ax1.set_title("ì£¼ì œë³„ ì²­ì› ë¶„í¬")
        fig1.savefig('/content/topic.png')
        st.image('/content/topic.png')

    # Column 2
    with col2:
        st.subheader("ì²­ì› ë™ì˜ ìˆ˜")
        grouped_by_agreements = data.groupby("ë¶„ì•¼")["ë™ì˜ìˆ˜"].sum().sort_values(ascending=False)  # ì£¼ì œë³„ ë™ì˜ ìˆ˜ í•©ì‚°
        fig2, ax2 = plt.subplots()
        ax2.bar(
            grouped_by_agreements.index, 
            grouped_by_agreements.values, 
            color="skyblue"
        )
        ax2.set_title("ì²­ì› ì£¼ì œë³„ ë™ì˜ ìˆ˜")
        ax2.set_ylabel("ë™ì˜ ìˆ˜")
        ax2.set_xlabel("ì²­ì› ì£¼ì œ")
        plt.xticks(rotation=45)
        fig2.savefig('/content/nums.png')
        st.image('/content/nums.png')

import streamlit as st
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.sequence import pad_sequences
import joblib
from konlpy.tag import Okt

# ëª¨ë¸ ë° í† í¬ë‚˜ì´ì € ë¡œë“œ
@st.cache_resource  # ìºì‹±ì„ í†µí•´ ë¡œë“œ ì‹œê°„ì„ ë‹¨ì¶•
def load_resources():
    model = load_model("agreement_prediction_model.keras")
    with open("agreement_tokenizer.pkl", "rb") as f:
        tokenizer = joblib.load(f)
    return model, tokenizer

model, tokenizer = load_resources()

# í† í°í™” í•¨ìˆ˜ ì •ì˜
def tokenize_korean(text):
    okt = Okt()
    if not isinstance(text, str):
        text = ""
    return ' '.join(okt.nouns(text))

# ìƒˆë¡œìš´ ì²­ì› ì˜ˆì¸¡ í•¨ìˆ˜
def predict_agreement_probability(text, tokenizer, model, max_len=200):
    text_tokenized = tokenize_korean(text)
    seq = tokenizer.texts_to_sequences([text_tokenized])
    padded = pad_sequences(seq, maxlen=max_len)
    prob = model.predict(padded)[0][0]
    return prob

with st.sidebar:
# Streamlit ì•± êµ¬ì„±
    st.title("ì²­ì› ì˜ˆì¸¡ ëª¨ë¸")
    st.write("ì²­ì›ì´ 50,000 ë™ì˜ë¥¼ ì´ˆê³¼í•  í™•ë¥ ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.")

# ì…ë ¥ í…ìŠ¤íŠ¸
    input_text = st.text_area("ì²­ì› ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”:", height=200)

# ì˜ˆì¸¡ ë²„íŠ¼
    if st.button("ì˜ˆì¸¡í•˜ê¸°"):
        if input_text.strip():
            prob = predict_agreement_probability(input_text, tokenizer, model, max_len=200)
            st.success(f"ì˜ˆì¸¡ëœ í™•ë¥ : {prob:.4f}")
        else:
            st.error("ì²­ì› ë‚´ìš©ì„ ì…ë ¥í•˜ì„¸ìš”.")
